PlaNet
======



Results
------------


Requirements
------------

- Python 3
- [DeepMind Control Suite](https://github.com/deepmind/dm_control) (optional)
- [Gym](https://gym.openai.com/)
- [OpenCV Python](https://pypi.python.org/pypi/opencv-python)
- [Plotly](https://plot.ly/)
- [PyTorch](http://pytorch.org/)


Links
-----

- [Overcoming the limits of DRL using a model-based approach](https://drlux.github.io/planpix.html)
- [Introducing PlaNet: A Deep Planning Network for Reinforcement Learning](https://ai.googleblog.com/2019/02/introducing-planet-deep-planning.html)
- [Kaixhin/planet](https://github.com/Kaixhin/PlaNet)
- [google-research/planet](https://github.com/google-research/planet)

Acknowledgements
----------------

- [@Kaixhin](https://github.com/Kaixhin/PlaNet) for its reimplementation of [google-research/planet](https://github.com/google-research/planet) 

References
----------

[1] [Learning Latent Dynamics for Planning from Pixels](https://arxiv.org/abs/1811.04551)  
[2] [Overcoming the limits of DRL using a model-based approach](https://drlux.github.io/planpix.html)

